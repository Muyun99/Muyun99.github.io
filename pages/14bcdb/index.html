<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>基于深度学习的图像分割技术 | Muyun99&#39;s wiki</title>
    <meta name="generator" content="VuePress 1.8.0">
    <link rel="icon" href="/img/favicon.ico">
    <script data-ad-client="ca-pub-7828333725993554" async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <meta name="description" content="">
    <meta name="keywords" content="">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    <link rel="preload" href="/assets/css/0.styles.bdefdc95.css" as="style"><link rel="preload" href="/assets/js/app.2164cc85.js" as="script"><link rel="preload" href="/assets/js/2.3a0f33d3.js" as="script"><link rel="preload" href="/assets/js/84.76bc15ac.js" as="script"><link rel="prefetch" href="/assets/js/10.5f46a7f2.js"><link rel="prefetch" href="/assets/js/100.46109e18.js"><link rel="prefetch" href="/assets/js/101.0826705d.js"><link rel="prefetch" href="/assets/js/102.5129cfd9.js"><link rel="prefetch" href="/assets/js/103.e0fad8e4.js"><link rel="prefetch" href="/assets/js/104.612f9d15.js"><link rel="prefetch" href="/assets/js/105.8f0d5447.js"><link rel="prefetch" href="/assets/js/106.59c5fbc8.js"><link rel="prefetch" href="/assets/js/107.bebb8c9f.js"><link rel="prefetch" href="/assets/js/108.73079467.js"><link rel="prefetch" href="/assets/js/109.7e815f7f.js"><link rel="prefetch" href="/assets/js/11.ba219e7b.js"><link rel="prefetch" href="/assets/js/110.6d8ffbe6.js"><link rel="prefetch" href="/assets/js/111.0531213b.js"><link rel="prefetch" href="/assets/js/112.f2c859c0.js"><link rel="prefetch" href="/assets/js/113.bc71ae69.js"><link rel="prefetch" href="/assets/js/114.26822f49.js"><link rel="prefetch" href="/assets/js/115.6512eecb.js"><link rel="prefetch" href="/assets/js/116.e224aaba.js"><link rel="prefetch" href="/assets/js/117.05e718a6.js"><link rel="prefetch" href="/assets/js/118.597ca212.js"><link rel="prefetch" href="/assets/js/119.5da78682.js"><link rel="prefetch" href="/assets/js/12.92eba91b.js"><link rel="prefetch" href="/assets/js/120.e581a0ee.js"><link rel="prefetch" href="/assets/js/121.be2c67fc.js"><link rel="prefetch" href="/assets/js/122.70e6b4e5.js"><link rel="prefetch" href="/assets/js/123.8296bcad.js"><link rel="prefetch" href="/assets/js/124.219f9074.js"><link rel="prefetch" href="/assets/js/125.42980d68.js"><link rel="prefetch" href="/assets/js/126.e0470fe1.js"><link rel="prefetch" href="/assets/js/127.2614a3ff.js"><link rel="prefetch" href="/assets/js/128.3894968d.js"><link rel="prefetch" href="/assets/js/129.bfd89640.js"><link rel="prefetch" href="/assets/js/13.41875a03.js"><link rel="prefetch" href="/assets/js/130.ca6af328.js"><link rel="prefetch" href="/assets/js/131.ce3547e9.js"><link rel="prefetch" href="/assets/js/132.c7adae59.js"><link rel="prefetch" href="/assets/js/133.7b148e67.js"><link rel="prefetch" href="/assets/js/134.26ce87d7.js"><link rel="prefetch" href="/assets/js/135.c0e6a63b.js"><link rel="prefetch" href="/assets/js/136.a846f868.js"><link rel="prefetch" href="/assets/js/137.01ef0c79.js"><link rel="prefetch" href="/assets/js/138.25845e03.js"><link rel="prefetch" href="/assets/js/139.f87d8dfb.js"><link rel="prefetch" href="/assets/js/14.4ea6e58b.js"><link rel="prefetch" href="/assets/js/140.a1e0adb4.js"><link rel="prefetch" href="/assets/js/141.8d294e46.js"><link rel="prefetch" href="/assets/js/142.f31a107d.js"><link rel="prefetch" href="/assets/js/143.962c12e1.js"><link rel="prefetch" href="/assets/js/144.3e126a2f.js"><link rel="prefetch" href="/assets/js/145.e872c634.js"><link rel="prefetch" href="/assets/js/146.ca3b3894.js"><link rel="prefetch" href="/assets/js/147.4ea23a80.js"><link rel="prefetch" href="/assets/js/148.4913751c.js"><link rel="prefetch" href="/assets/js/149.674df5e3.js"><link rel="prefetch" href="/assets/js/15.6315eebb.js"><link rel="prefetch" href="/assets/js/150.afbba495.js"><link rel="prefetch" href="/assets/js/151.244001f4.js"><link rel="prefetch" href="/assets/js/152.2138506a.js"><link rel="prefetch" href="/assets/js/153.096b6935.js"><link rel="prefetch" href="/assets/js/154.e3cfefa3.js"><link rel="prefetch" href="/assets/js/155.f7b4183e.js"><link rel="prefetch" href="/assets/js/156.d45d8fd9.js"><link rel="prefetch" href="/assets/js/157.fc653f4e.js"><link rel="prefetch" href="/assets/js/158.cad10f7d.js"><link rel="prefetch" href="/assets/js/159.adae05f6.js"><link rel="prefetch" href="/assets/js/16.a45707b9.js"><link rel="prefetch" href="/assets/js/160.828f88c1.js"><link rel="prefetch" href="/assets/js/161.20f3e039.js"><link rel="prefetch" href="/assets/js/162.cba07e9b.js"><link rel="prefetch" href="/assets/js/163.7783a35f.js"><link rel="prefetch" href="/assets/js/164.d3618df9.js"><link rel="prefetch" href="/assets/js/165.b2823237.js"><link rel="prefetch" href="/assets/js/166.11c27ec7.js"><link rel="prefetch" href="/assets/js/167.1b89c7f0.js"><link rel="prefetch" href="/assets/js/168.70c6c64f.js"><link rel="prefetch" href="/assets/js/169.73a1cf13.js"><link rel="prefetch" href="/assets/js/17.84b8189a.js"><link rel="prefetch" href="/assets/js/170.6529cd0e.js"><link rel="prefetch" href="/assets/js/171.eca471df.js"><link rel="prefetch" href="/assets/js/172.c37b1d1b.js"><link rel="prefetch" href="/assets/js/173.01d9640c.js"><link rel="prefetch" href="/assets/js/174.39b4e30a.js"><link rel="prefetch" href="/assets/js/175.42d99e11.js"><link rel="prefetch" href="/assets/js/176.66f3bf94.js"><link rel="prefetch" href="/assets/js/177.2f72339e.js"><link rel="prefetch" href="/assets/js/178.157bc1aa.js"><link rel="prefetch" href="/assets/js/179.f5fa8abc.js"><link rel="prefetch" href="/assets/js/18.7ef19f81.js"><link rel="prefetch" href="/assets/js/180.2d524cfa.js"><link rel="prefetch" href="/assets/js/181.94dd9ddd.js"><link rel="prefetch" href="/assets/js/182.e974805c.js"><link rel="prefetch" href="/assets/js/183.798e5d4f.js"><link rel="prefetch" href="/assets/js/184.6a8c5be6.js"><link rel="prefetch" href="/assets/js/185.18142647.js"><link rel="prefetch" href="/assets/js/186.84160426.js"><link rel="prefetch" href="/assets/js/187.49ee8f2f.js"><link rel="prefetch" href="/assets/js/188.836016f5.js"><link rel="prefetch" href="/assets/js/189.ff83730a.js"><link rel="prefetch" href="/assets/js/19.fe8ba7a9.js"><link rel="prefetch" href="/assets/js/190.c7e999fe.js"><link rel="prefetch" href="/assets/js/191.fb777610.js"><link rel="prefetch" href="/assets/js/192.fe572b1a.js"><link rel="prefetch" href="/assets/js/193.ebbb0341.js"><link rel="prefetch" href="/assets/js/194.fc098f07.js"><link rel="prefetch" href="/assets/js/195.bdb2ad5c.js"><link rel="prefetch" href="/assets/js/196.e868eaa0.js"><link rel="prefetch" href="/assets/js/197.79638251.js"><link rel="prefetch" href="/assets/js/198.9c32057b.js"><link rel="prefetch" href="/assets/js/199.5fbb8d5a.js"><link rel="prefetch" href="/assets/js/20.6b22eb76.js"><link rel="prefetch" href="/assets/js/200.fd915906.js"><link rel="prefetch" href="/assets/js/201.deb6d35c.js"><link rel="prefetch" href="/assets/js/202.4b0e4bb8.js"><link rel="prefetch" href="/assets/js/203.9cb27cec.js"><link rel="prefetch" href="/assets/js/204.9772dbfe.js"><link rel="prefetch" href="/assets/js/205.46709f69.js"><link rel="prefetch" href="/assets/js/206.8838ac9a.js"><link rel="prefetch" href="/assets/js/207.1207b594.js"><link rel="prefetch" href="/assets/js/208.9d545170.js"><link rel="prefetch" href="/assets/js/209.48cef5cc.js"><link rel="prefetch" href="/assets/js/21.2b69be72.js"><link rel="prefetch" href="/assets/js/210.35875a85.js"><link rel="prefetch" href="/assets/js/211.1ef507f5.js"><link rel="prefetch" href="/assets/js/212.e40db2e4.js"><link rel="prefetch" href="/assets/js/213.5d5b825b.js"><link rel="prefetch" href="/assets/js/214.e0167929.js"><link rel="prefetch" href="/assets/js/215.b3dacfbe.js"><link rel="prefetch" href="/assets/js/216.6a6b8867.js"><link rel="prefetch" href="/assets/js/217.ad89b973.js"><link rel="prefetch" href="/assets/js/218.e6c353a0.js"><link rel="prefetch" href="/assets/js/219.78d57472.js"><link rel="prefetch" href="/assets/js/22.a171d265.js"><link rel="prefetch" href="/assets/js/220.0587014d.js"><link rel="prefetch" href="/assets/js/221.b02bd13b.js"><link rel="prefetch" href="/assets/js/222.77d7b68d.js"><link rel="prefetch" href="/assets/js/223.989fa28e.js"><link rel="prefetch" href="/assets/js/224.f26de2a0.js"><link rel="prefetch" href="/assets/js/225.3d0828ec.js"><link rel="prefetch" href="/assets/js/226.194d710e.js"><link rel="prefetch" href="/assets/js/227.f9768256.js"><link rel="prefetch" href="/assets/js/228.41593a37.js"><link rel="prefetch" href="/assets/js/229.6a592fa1.js"><link rel="prefetch" href="/assets/js/23.d812c568.js"><link rel="prefetch" href="/assets/js/230.3c6fdea6.js"><link rel="prefetch" href="/assets/js/231.0fc24bb2.js"><link rel="prefetch" href="/assets/js/232.f381122a.js"><link rel="prefetch" href="/assets/js/233.d1d5bacf.js"><link rel="prefetch" href="/assets/js/234.4af5f5d4.js"><link rel="prefetch" href="/assets/js/235.f252f22f.js"><link rel="prefetch" href="/assets/js/236.7de67ddb.js"><link rel="prefetch" href="/assets/js/237.47ced467.js"><link rel="prefetch" href="/assets/js/238.1a33fd51.js"><link rel="prefetch" href="/assets/js/239.b696499c.js"><link rel="prefetch" href="/assets/js/24.72ac623b.js"><link rel="prefetch" href="/assets/js/240.16d96df4.js"><link rel="prefetch" href="/assets/js/241.691185aa.js"><link rel="prefetch" href="/assets/js/242.377e1fd2.js"><link rel="prefetch" href="/assets/js/243.4ed38de5.js"><link rel="prefetch" href="/assets/js/244.586adc48.js"><link rel="prefetch" href="/assets/js/245.11f2a36a.js"><link rel="prefetch" href="/assets/js/246.1ddf3941.js"><link rel="prefetch" href="/assets/js/247.d25ea987.js"><link rel="prefetch" href="/assets/js/248.71958f1a.js"><link rel="prefetch" href="/assets/js/25.fb468557.js"><link rel="prefetch" href="/assets/js/26.e7dda852.js"><link rel="prefetch" href="/assets/js/27.467f0322.js"><link rel="prefetch" href="/assets/js/28.426290bc.js"><link rel="prefetch" href="/assets/js/29.225ecc7e.js"><link rel="prefetch" href="/assets/js/3.15429d0b.js"><link rel="prefetch" href="/assets/js/30.fa7560f8.js"><link rel="prefetch" href="/assets/js/31.a8fc66f3.js"><link rel="prefetch" href="/assets/js/32.ac50becc.js"><link rel="prefetch" href="/assets/js/33.59608a34.js"><link rel="prefetch" href="/assets/js/34.68a0dbe3.js"><link rel="prefetch" href="/assets/js/35.6336ae0a.js"><link rel="prefetch" href="/assets/js/36.f9d748d4.js"><link rel="prefetch" href="/assets/js/37.85b39d58.js"><link rel="prefetch" href="/assets/js/38.b2d7cfc8.js"><link rel="prefetch" href="/assets/js/39.8c3fc57c.js"><link rel="prefetch" href="/assets/js/4.1cd3e40a.js"><link rel="prefetch" href="/assets/js/40.b67b358c.js"><link rel="prefetch" href="/assets/js/41.c5473fd5.js"><link rel="prefetch" href="/assets/js/42.12286784.js"><link rel="prefetch" href="/assets/js/43.758498fe.js"><link rel="prefetch" href="/assets/js/44.621d6d70.js"><link rel="prefetch" href="/assets/js/45.7344cb95.js"><link rel="prefetch" href="/assets/js/46.02c79e51.js"><link rel="prefetch" href="/assets/js/47.bc1cde90.js"><link rel="prefetch" href="/assets/js/48.00eb4363.js"><link rel="prefetch" href="/assets/js/49.e0368bdc.js"><link rel="prefetch" href="/assets/js/5.1ef7651e.js"><link rel="prefetch" href="/assets/js/50.11151480.js"><link rel="prefetch" href="/assets/js/51.39f64147.js"><link rel="prefetch" href="/assets/js/52.58c3f1e5.js"><link rel="prefetch" href="/assets/js/53.3689ff3f.js"><link rel="prefetch" href="/assets/js/54.9a425b4c.js"><link rel="prefetch" href="/assets/js/55.d5837e6a.js"><link rel="prefetch" href="/assets/js/56.4f6a4a6d.js"><link rel="prefetch" href="/assets/js/57.78ad9bd8.js"><link rel="prefetch" href="/assets/js/58.7a4a19db.js"><link rel="prefetch" href="/assets/js/59.3cd8b88a.js"><link rel="prefetch" href="/assets/js/6.f2219599.js"><link rel="prefetch" href="/assets/js/60.5dfcb925.js"><link rel="prefetch" href="/assets/js/61.50246c0b.js"><link rel="prefetch" href="/assets/js/62.94b3d244.js"><link rel="prefetch" href="/assets/js/63.5d1c7582.js"><link rel="prefetch" href="/assets/js/64.7e504dbe.js"><link rel="prefetch" href="/assets/js/65.0ab7d7f5.js"><link rel="prefetch" href="/assets/js/66.9b1e5832.js"><link rel="prefetch" href="/assets/js/67.a49a0072.js"><link rel="prefetch" href="/assets/js/68.89a2cdb9.js"><link rel="prefetch" href="/assets/js/69.7c51a497.js"><link rel="prefetch" href="/assets/js/7.24d16974.js"><link rel="prefetch" href="/assets/js/70.fa17088f.js"><link rel="prefetch" href="/assets/js/71.652bc609.js"><link rel="prefetch" href="/assets/js/72.a8b644d6.js"><link rel="prefetch" href="/assets/js/73.96493a6a.js"><link rel="prefetch" href="/assets/js/74.6e32cc3b.js"><link rel="prefetch" href="/assets/js/75.5575a872.js"><link rel="prefetch" href="/assets/js/76.553e4468.js"><link rel="prefetch" href="/assets/js/77.78664d5a.js"><link rel="prefetch" href="/assets/js/78.4e68102a.js"><link rel="prefetch" href="/assets/js/79.26a5da26.js"><link rel="prefetch" href="/assets/js/8.0fc65535.js"><link rel="prefetch" href="/assets/js/80.628040bb.js"><link rel="prefetch" href="/assets/js/81.f8aa9e53.js"><link rel="prefetch" href="/assets/js/82.4d269dab.js"><link rel="prefetch" href="/assets/js/83.e451c303.js"><link rel="prefetch" href="/assets/js/85.52941df8.js"><link rel="prefetch" href="/assets/js/86.9afbfc8c.js"><link rel="prefetch" href="/assets/js/87.da83cc25.js"><link rel="prefetch" href="/assets/js/88.f2829fa6.js"><link rel="prefetch" href="/assets/js/89.cb138ae1.js"><link rel="prefetch" href="/assets/js/9.a6c1a71e.js"><link rel="prefetch" href="/assets/js/90.8192237b.js"><link rel="prefetch" href="/assets/js/91.109a9a1b.js"><link rel="prefetch" href="/assets/js/92.ffdd8c48.js"><link rel="prefetch" href="/assets/js/93.ffbf1b0a.js"><link rel="prefetch" href="/assets/js/94.d50a2400.js"><link rel="prefetch" href="/assets/js/95.8db673cc.js"><link rel="prefetch" href="/assets/js/96.9071a7e6.js"><link rel="prefetch" href="/assets/js/97.0f525bfd.js"><link rel="prefetch" href="/assets/js/98.dccba0c1.js"><link rel="prefetch" href="/assets/js/99.ba1fcb5f.js">
    <link rel="stylesheet" href="/assets/css/0.styles.bdefdc95.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/EB-logo.png" alt="Muyun99's wiki" class="logo"> <span class="site-name can-hide">Muyun99's wiki</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/wiki/" class="nav-link">wiki搬运</a></div><div class="nav-item"><a href="/resources/" class="nav-link">资源收藏</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/tutou.jpg"> <div class="blogger-info"><h3>Muyun99</h3> <span>努力成为一个善良的人</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/research/" class="nav-link">学术搬砖</a></div><div class="nav-item"><a href="/notes/" class="nav-link">学习笔记</a></div><div class="nav-item"><a href="/life/" class="nav-link">生活杂谈</a></div><div class="nav-item"><a href="/wiki/" class="nav-link">wiki搬运</a></div><div class="nav-item"><a href="/resources/" class="nav-link">资源收藏</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>代码实践-目标检测</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>代码实践-图像分割</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/14bcdb/" aria-current="page" class="active sidebar-link">基于深度学习的图像分割技术</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/pages/7302ec/" class="sidebar-link">领域自适应</a></li><li><a href="/pages/4e1e41/" class="sidebar-link">如何计算一个模型的FPS,Params,GFLOPs</a></li><li><a href="/pages/679017/" class="sidebar-link">常见数据集的相关知识</a></li><li><a href="/pages/80ffb0/" class="sidebar-link">如何加载数据集</a></li><li><a href="/pages/b8e080/" class="sidebar-link">半监督与弱监督图像分割</a></li><li><a href="/pages/15a0e4/" class="sidebar-link">PASCAL VOC 2012调色板 color map生成源代码分析</a></li><li><a href="/pages/f64db3/" class="sidebar-link">语义分割数据集灰度分割图转彩色分割图代码</a></li><li><a href="/pages/5e185e/" class="sidebar-link">复现PSA</a></li><li><a href="/pages/6c2aa7/" class="sidebar-link">转换cityscapes 到对应的类别</a></li><li><a href="/pages/ce4f65/" class="sidebar-link">上采样函数</a></li><li><a href="/pages/181ce5/" class="sidebar-link">DeepLab系列代码</a></li><li><a href="/pages/f55018/" class="sidebar-link">mIoU的计算</a></li><li><a href="/pages/a0a28d/" class="sidebar-link">Multi-label 分类中如何计算 mAP</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>代码实践-自监督学习</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>竞赛笔记-视觉竞赛</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>框架解析-mmlab系列</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>讲座记录-有意思的文章集合</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>体会感悟-产品沉思录观后有感</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>体会感悟-摄影</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-乐理和五线谱</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-爬虫实践</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-Django学习笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-Git 使用笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-网站搭建</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-图卷积网络</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>课程笔记-MIT-NULL</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-OpenCV-Python</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-使用 Beancount 记账</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-Python设计模式</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-MLOps</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-Apollo自动驾驶</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-PaddlePaddle</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>系列笔记-视频操作</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Vue+Django前后端分离开发</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>深度学习及机器学习理论知识学习笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>PyTorch Tricks</span> <span class="arrow right"></span></p> <!----></section></li></ul> <div class="sidebar-slot sidebar-slot-bottom"><!-- 正方形 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="3508773082"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div></aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-33863c7e><div class="articleInfo" data-v-33863c7e><ul class="breadcrumbs" data-v-33863c7e><li data-v-33863c7e><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-33863c7e></a></li> <li data-v-33863c7e><a href="/notes" title="学习笔记-目录页" data-v-33863c7e>学习笔记</a></li> <li data-v-33863c7e><a href="/notes/#代码实践-图像分割" title="学习笔记#代码实践-图像分割" data-v-33863c7e>代码实践-图像分割</a></li> <!----></ul> <div class="info" data-v-33863c7e><div title="作者" class="author iconfont icon-touxiang" data-v-33863c7e><a href="https://github.com/Muyun99" target="_blank" title="作者" class="beLink" data-v-33863c7e>Muyun99</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-33863c7e><a href="javascript:;" data-v-33863c7e>2021-04-14</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">
          基于深度学习的图像分割技术
        </h1> <div class="page-slot page-slot-top"><!-- 固定100% * 90px可显示，max-height:90px未见显示-->
     <ins class="adsbygoogle"
          style="display:inline-block;width:100%;max-height:90px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6625304284"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="theme-vdoing-content content__default"><h3 id="语义分割入门"><a href="#语义分割入门" class="header-anchor">#</a> 语义分割入门</h3> <h4 id="什么是语义分割"><a href="#什么是语义分割" class="header-anchor">#</a> 什么是语义分割</h4> <p>图像分割是许多视觉理解系统中必不可少的组成部分，在医学影像分析、机器人感知、 视频监控、自动驾驶等领域都有着十分重要的地位。图像分割任务可以理解为基于语义信息和实例信息的像素级别的分类问题。</p> <p>参考资料：<a href="https://zhuanlan.zhihu.com/p/48670341" target="_blank" rel="noopener noreferrer">语义分割-从入门到放弃<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h4 id="语义分割的发展现状"><a href="#语义分割的发展现状" class="header-anchor">#</a> 语义分割的发展现状</h4> <p>FCN利用了全卷积网络产生特征，输入空间映射，实现了端到端的语义分割任务，成为深度学习技术应用于语义分割问题的基石。U-Net 通过上采样和 skip connection 融合高低层的特征信息，获得了更加精准的分割结果。SegNet 使用 Maxpooling indices 来增强位置信息，提高了 SegNet 的效率。</p> <p>也有学者提出了 DeepLab 算法[3,20–22]，经过不断演进后共有四个版本。DeepLabv1 模 型[3] 将深度卷积神经网络和概率图模型进行结合。作者指出：深度卷积神经网络下采样导 致细节信息丢失，并且其结构会限制空间定位精度，该算法则使用空洞卷积以及条件随机 场对模型进行了改进。空洞卷积，在保证较大感受野的同时不过分下采样丢失过多细节信 息。条件随机场用于接收卷积神经网络的最后一层的响应进行后处理，以较少的时间内完 成细粒度的定位。DeepLabv1 将卷积神经网络和条件随机场进行耦合，并且使用多尺度预 测方法提高了边界定位精度，能够较好的恢复对象边缘信息，在 GPU 上能够达到 8 FPS 的速度。DeepLabv2[20] 将下采样的层全部替换为空洞卷积，以更高的采样密度来计算特征 映射，其特征提取模块也从 VGG[9] 换到了 ResNet[11]，加强了网络的特征提取能力。作者 还提出了基于空洞卷积的空间池化金字塔（ASPP）模块，以不同采样率的空洞卷积进行 采样，以多个比例学习图像的上下文信息，丰富了特征的维度。DeepLabv3[21] 取消了前两 个版本中的条件随机场的后处理，重点关注了四种利用上下文信息的网络模块，包括图像 金字塔、编码器-解码器、上下文模块、空间金字塔池化。该算法加深了网络深度，同时调 整了网络的下采样率，减少信息的丢失，级联模块进行特征提取后，将特征输入到结合图 像级别特征的空间金字塔池化模块，完成了整个网络结构的搭建。作者在这些模块的搭建 了进行了大量的实验验证，最终演化出最终的结构，在 PASCAL VOC 2012 数据集上的测 试性能的达到了当时的最优水平。DeepLabv3+[22] 使用空洞卷积的 Xception[15] 进行特征采 样，其网络结构见图 2.4。作者在 DeepLabv3 的基础上添加了 Decoder 模块，将 Xception 提取出的特征与 ASPP 模块采样后的特征进行特征融合后共同上采样恢复图像分辨率，使 整个模型成为编码器-解码器结构。解码器模块可以获得更好的边界分割效果，有助于模型 性能的提升。</p> <p>RefineNet 精心设计了 Decoder 模块，并且增加了 residual connections，提升了网络的表达能力。讨论了空洞卷积的缺点。PSPNet 使用pyramid pooling整合context，使用auxiliary loss 提升网络的学习能力。DANet DANet是一种经典的应用self-Attention的网络，它引入了一种**自注意力机制来分别捕获空间维度和通道维度中的特征依赖关系。**提出了双重注意网络（DANet）来自适应地集成局部特征和全局依赖。在传统的扩张FCN之上附加两种类型的注意力模块，分别模拟空间和通道维度中的语义相互依赖性。</p> <p><strong>HRNet通过并行多个分辨率的分支，加上不断进行不同分支之间的信息交互，同时达到强语义信息和精准位置信息的目的。<strong>我觉得</strong>最大的创新点还是能够从头到尾保持高分辨率，而不同分支的信息交互是为了补充通道数减少带来的信息损耗</strong>。OCR 方法提出的物体上下文信息的目的在于显式地增强物体信息，通过计算一组物体的区域特征表达，根据物体区域特征表示与像素特征表示之间的相似度将这些物体区域特征表示传播给每一个像素。</p> <p>PointRend 把语义分割以及实例分割问题（统称图像分割问题）当做一个渲染问题来解决。<strong>但本质上这篇论文其实是一个新型上采样方法，针对物体边缘的图像分割进行优化，使其在难以分割的物体边缘部分有更好的表现</strong>。</p> <h3 id="摘录了-cityscapes-数据集上的语义分割数据集的精度"><a href="#摘录了-cityscapes-数据集上的语义分割数据集的精度" class="header-anchor">#</a> 摘录了 Cityscapes 数据集上的语义分割数据集的精度</h3> <p>https://paperswithcode.com/sota/semantic-segmentation-on-cityscapes</p> <p>1、2014 DeepLab 63.1%</p> <p><a href="https://paperswithcode.com/paper/semantic-image-segmentation-with-deep" target="_blank" rel="noopener noreferrer">Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>2、2014 FCN 65.3%</p> <p><a href="https://paperswithcode.com/paper/fully-convolutional-networks-for-semantic" target="_blank" rel="noopener noreferrer">Fully Convolutional Networks for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>3、2015 SegNet 57.0%</p> <p><a href="https://paperswithcode.com/paper/segnet-a-deep-convolutional-encoder-decoder" target="_blank" rel="noopener noreferrer">SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>5、2016 DeepLab-CRF (ResNet-101) 70.4%</p> <p><a href="https://paperswithcode.com/paper/deeplab-semantic-image-segmentation-with-deep" target="_blank" rel="noopener noreferrer">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>6、2016 RefineNet (ResNet-101) 73.6%</p> <p><a href="https://paperswithcode.com/paper/refinenet-multi-path-refinement-networks-for" target="_blank" rel="noopener noreferrer">RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>7、2016 PSPNet (ResNet-101) 81.2%</p> <p><a href="https://paperswithcode.com/paper/pyramid-scene-parsing-network" target="_blank" rel="noopener noreferrer">Pyramid Scene Parsing Network<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>9、2017 DeepLabv3 (ResNet-101 coarse)</p> <p><a href="https://paperswithcode.com/paper/rethinking-atrous-convolution-for-semantic" target="_blank" rel="noopener noreferrer">Rethinking Atrous Convolution for Semantic Image Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>13、2018 DenseASPP  (DenseNet-161) 80.6%</p> <p><a href="https://paperswithcode.com/paper/denseaspp-for-semantic-segmentation-in-street" target="_blank" rel="noopener noreferrer">DenseASPP for Semantic Segmentation in Street Scenes<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>14、2018 PSANet (ResNet-101) 81.4%</p> <p><a href="https://paperswithcode.com/paper/psanet-point-wise-spatial-attention-network" target="_blank" rel="noopener noreferrer">PSANet: Point-wise Spatial Attention Network for Scene Parsing<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>15、2018 CCNet 81.4%</p> <p><a href="https://paperswithcode.com/paper/ccnet-criss-cross-attention-for-semantic" target="_blank" rel="noopener noreferrer">CCNet: Criss-Cross Attention for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>16、2018 DANet 81.5%</p> <p><a href="https://paperswithcode.com/paper/dual-attention-network-for-scene-segmentation" target="_blank" rel="noopener noreferrer">Dual Attention Network for Scene Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>17、2018 OCNet 81.7%</p> <p><a href="https://paperswithcode.com/paper/ocnet-object-context-network-for-scene" target="_blank" rel="noopener noreferrer">OCNet: Object Context Network for Scene Parsing<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>18、2018 DeepLabv3+ (Xception-JFT) 82.1%</p> <p><a href="https://paperswithcode.com/paper/encoder-decoder-with-atrous-separable" target="_blank" rel="noopener noreferrer">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>19、2018 DeepLabv3Plus + SDCNetAug 83.5%</p> <p><a href="https://paperswithcode.com/paper/improving-semantic-segmentation-via-video" target="_blank" rel="noopener noreferrer">Improving Semantic Segmentation via Video Propagation and Label Relaxation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>20、2019 Asymmetric ALNN 81.3%</p> <p><a href="https://paperswithcode.com/paper/asymmetric-non-local-neural-networks-for" target="_blank" rel="noopener noreferrer">Asymmetric Non-local Neural Networks for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>21、2019 BFP 81.4%</p> <p><a href="https://paperswithcode.com/paper/boundary-aware-feature-propagation-for-scene" target="_blank" rel="noopener noreferrer">Boundary-Aware Feature Propagation for Scene Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>22、2019 HRNet (HRNetV2-W48) 81.6%</p> <p><a href="https://paperswithcode.com/paper/high-resolution-representations-for-labeling" target="_blank" rel="noopener noreferrer">High-Resolution Representations for Labeling Pixels and Regions<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>23、2019 OCR (ResNet-101) 81.8%</p> <p><a href="https://paperswithcode.com/paper/object-contextual-representations-for" target="_blank" rel="noopener noreferrer">Object-Contextual Representations for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>24、2019 Auto-DeepLab-L 82.1%</p> <p><a href="https://paperswithcode.com/paper/auto-deeplab-hierarchical-neural-architecture" target="_blank" rel="noopener noreferrer">Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>25、2019 OCR (ResNet-101 coarse) 82.4%</p> <p>见第 23 条</p> <p>26、2019 OCR (HRNetV2-W48 coarse) 83.0%</p> <p>见第 23 条</p> <p>27、2019 HRNetV2+OCR (w/ASP) 83.7%</p> <p>见第 23 条</p> <p>28、2019 Panoptic-DeepLab 84.2%</p> <p><a href="https://paperswithcode.com/paper/panoptic-deeplab-a-simple-strong-and-fast" target="_blank" rel="noopener noreferrer">Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>29、2019 HRNetV2 + OCR + extra data 84.5%</p> <p>见第 23 条</p> <p>30、2020 ESANet-R34-NBt1D 80.09%</p> <p><a href="https://paperswithcode.com/paper/efficient-rgb-d-semantic-segmentation-for" target="_blank" rel="noopener noreferrer">Efficient RGB-D Semantic Segmentation for Indoor Scene Analysis<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>31、2020 CPN (ResNet-101) 81.3%</p> <p><a href="https://paperswithcode.com/paper/context-prior-for-scene-segmentation" target="_blank" rel="noopener noreferrer">Context Prior for Scene Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>32、2020 HANet 83.2%</p> <p><a href="https://paperswithcode.com/paper/cars-cant-fly-up-in-the-sky-improving-urban" target="_blank" rel="noopener noreferrer">Cars Can't Fly up in the Sky: Improving Urban-Scene Segmentation via Height-driven Attention Networks<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>33、2020 ResNest200 83.3%</p> <p><a href="https://paperswithcode.com/paper/resnest-split-attention-networks" target="_blank" rel="noopener noreferrer">ResNeSt: Split-Attention Networks<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>34、2020 EfficientPS 84.21%</p> <p><a href="https://paperswithcode.com/paper/efficientps-efficient-panoptic-segmentation" target="_blank" rel="noopener noreferrer">EfficientPS: Efficient Panoptic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>35、2020 HRNet-OCR(Hierarchical Multi-Scale Attention) 85.1%</p> <p><a href="https://paperswithcode.com/paper/hierarchical-multi-scale-attention-for" target="_blank" rel="noopener noreferrer">Hierarchical Multi-Scale Attention for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>36、2021 DDRNet-39 1.5x 82.4%</p> <p><a href="https://paperswithcode.com/paper/deep-dual-resolution-networks-for-real-time" target="_blank" rel="noopener noreferrer">Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>37、2021 CCA (ResNet-101) 82.6%</p> <p><a href="https://paperswithcode.com/paper/caa-channelized-axial-attention-for-semantic" target="_blank" rel="noopener noreferrer">CAA : Channelized Axial Attention for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>38、2021 SETR</p> <ul><li>paper: <a href="https://github.com/fudan-zvg/SETR" target="_blank" rel="noopener noreferrer">[CVPR 2021] Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>code: [<a href="https://arxiv.org/abs/2012.15840" target="_blank" rel="noopener noreferrer">Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>参考资料：</p> <p><a href="https://zhuanlan.zhihu.com/p/36857546" target="_blank" rel="noopener noreferrer">语义分割刷怪进阶<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h3 id="实时语义分割"><a href="#实时语义分割" class="header-anchor">#</a> 实时语义分割</h3> <p>1、2016 ENet 58.3%</p> <ul><li><a href="https://paperswithcode.com/paper/enet-a-deep-neural-network-architecture-for" target="_blank" rel="noopener noreferrer">ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>2、2017 ICNet 70.6%</p> <ul><li><a href="https://paperswithcode.com/paper/icnet-for-real-time-semantic-segmentation-on" target="_blank" rel="noopener noreferrer">ICNet for Real-Time Semantic Segmentation on High-Resolution Images<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>3、2018 ESPNet 60.3%</p> <ul><li>paper: <a href="https://paperswithcode.com/paper/espnet-efficient-spatial-pyramid-of-dilated" target="_blank" rel="noopener noreferrer">ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>code: <a href="https://github.com/sacmehta/ESPNet" target="_blank" rel="noopener noreferrer">ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>4、2018 ESPNetv2 66.2%</p> <ul><li><a href="https://paperswithcode.com/paper/espnetv2-a-light-weight-power-efficient-and" target="_blank" rel="noopener noreferrer">ESPNetv2: A Light-weight, Power Efficient, and General Purpose Convolutional Neural Network<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>5、2018 BiSeNet (ResNet-101) 78.9%</p> <ul><li><a href="https://paperswithcode.com/paper/bisenet-bilateral-segmentation-network-for" target="_blank" rel="noopener noreferrer">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>6、2019 ESNet 70.7%</p> <ul><li><a href="https://paperswithcode.com/paper/esnet-an-efficient-symmetric-network-for-real" target="_blank" rel="noopener noreferrer">ESNet: An Efficient Symmetric Network for Real-time Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>7、2019 DFANet A 71.3%</p> <ul><li><a href="https://paperswithcode.com/paper/dfanet-deep-feature-aggregation-for-real-time" target="_blank" rel="noopener noreferrer">DFANet: Deep Feature Aggregation for Real-Time Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>8、2019 FasterSeg 71.5%</p> <ul><li><a href="https://paperswithcode.com/paper/fasterseg-searching-for-faster-real-time-1" target="_blank" rel="noopener noreferrer">FasterSeg: Searching for Faster Real-time Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>9、2020 SFSegNet (ECCV 2020 Oral)</p> <ul><li>paper: <a href="https://arxiv.org/abs/2002.10120" target="_blank" rel="noopener noreferrer">Semantic Flow for Fast and Accurate Scene Parsing<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>code: <a href="https://github.com/donnyyou/torchcv" target="_blank" rel="noopener noreferrer">Implementation of Our ECCV-2020-oral paper: Semantic Flow for Fast and Accurate Scene Parsing<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>10、DecoupleSegNets (ECCV 2020)</p> <ul><li><p>paper: <a href="https://arxiv.org/abs/2007.10035" target="_blank" rel="noopener noreferrer">Improving Semantic Segmentation via Decoupled Body and Edge Supervision<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li> <li><p>code: <a href="https://github.com/lxtGH/DecoupleSegNets" target="_blank" rel="noopener noreferrer">Implementation of Our ECCV2020-work: Improving Semantic Segmentation via Decoupled Body and Edge Supervision<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li></ul> <p>10、2021 DDRNet</p> <ul><li><p>paper: <a href="https://arxiv.org/abs/2101.06085" target="_blank" rel="noopener noreferrer">Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li> <li><p>code: <a href="https://github.com/ydhongHIT/DDRNet" target="_blank" rel="noopener noreferrer">The official implementation of &quot;Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes&quot;<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li></ul> <p>参考资料：</p> <p><a href="https://zhuanlan.zhihu.com/p/268409221" target="_blank" rel="noopener noreferrer">实时语义分割 看这一篇就够了！涵盖24篇文章——上篇<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://zhuanlan.zhihu.com/p/268405193" target="_blank" rel="noopener noreferrer">实时语义分割 看这一篇就够了！涵盖24篇文章——下篇<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h3 id="实例分割"><a href="#实例分割" class="header-anchor">#</a> 实例分割</h3> <p>1、2021 BCNet（CVPR2021）</p> <ul><li>paper：<a href="https://arxiv.org/abs/2103.12340" target="_blank" rel="noopener noreferrer">Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>code：<a href="https://github.com/lkeab/BCNet" target="_blank" rel="noopener noreferrer">Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers [CVPR 2021]<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <h3 id="全景分割"><a href="#全景分割" class="header-anchor">#</a> 全景分割</h3> <p>1、2020 Axial-DeepLab (ECCV 2020 Spotlight)</p> <ul><li><p>paper: <a href="https://arxiv.org/abs/2003.07853" target="_blank" rel="noopener noreferrer">Axial-DeepLab: Stand-Alone Axial-Attention for Panoptic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li> <li><p>code: <a href="https://github.com/csrhddlam/axial-deeplab" target="_blank" rel="noopener noreferrer">This is a PyTorch re-implementation of Axial-DeepLab (ECCV 2020 Spotlight)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></li></ul> <p>2、2020 PanopticFCN（CVPR 2021 Oral）</p> <ul><li>paper：<a href="https://arxiv.org/abs/2012.00720" target="_blank" rel="noopener noreferrer">Fully Convolutional Networks for Panoptic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>code：<a href="https://github.com/Jia-Research-Lab/PanopticFCN" target="_blank" rel="noopener noreferrer">Fully Convolutional Networks for Panoptic Segmentation (CVPR2021 Oral)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>intro：<a href="https://mp.weixin.qq.com/s/UzgxAlPdW8BIGdnr_akqlg" target="_blank" rel="noopener noreferrer">Panoptic FCN：真正End-to-End的全景分割<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <h3 id="语义分割的-domain-adaptation"><a href="#语义分割的-domain-adaptation" class="header-anchor">#</a> 语义分割的 Domain Adaptation</h3> <p>1、2018 ADVENT（CVPR 2019）</p> <ul><li>paper: <a href="https://arxiv.org/abs/1811.12833" target="_blank" rel="noopener noreferrer">ADVENT: Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>code: <a href="https://github.com/valeoai/ADVENT" target="_blank" rel="noopener noreferrer">Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <h3 id="半监督分割"><a href="#半监督分割" class="header-anchor">#</a> 半监督分割</h3> <p>1、2021 DTML（arxiv）</p> <ul><li>paper：<a href="https://arxiv.org/abs/2103.04708" target="_blank" rel="noopener noreferrer">Dual-Task Mutual Learning for Semi-Supervised Medical Image Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li>code：<a href="https://github.com/YichiZhang98/DTML" target="_blank" rel="noopener noreferrer">Dual-Task Mutual Learning for Semi-Supervised Medical Image Segmentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <h3 id="分割的标注工具"><a href="#分割的标注工具" class="header-anchor">#</a> 分割的标注工具</h3> <p>1、Semantic Segmentation Editor</p> <ul><li>link：<a href="https://github.com/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor" target="_blank" rel="noopener noreferrer">Web labeling tool for bitmap images and point clouds<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <p>2、PixelAnnotationTool</p> <ul><li>link：<a href="https://github.com/abreheret/PixelAnnotationTool" target="_blank" rel="noopener noreferrer">PixelAnnotationTool<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <h3 id="分割的性能评估"><a href="#分割的性能评估" class="header-anchor">#</a> 分割的性能评估</h3> <p>1、Boundary IoU API</p> <ul><li>link: <a href="https://github.com/bowenc0221/boundary-iou-api" target="_blank" rel="noopener noreferrer">Boundary IoU API (Beta version)<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <div class="page-slot page-slot-bottom"><!-- 横向自适应 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6620245489"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="page-edit"><!----> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2021/08/02, 21:04:52</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/c06123/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">cowfits竞赛记录</div></a> <a href="/pages/7302ec/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">领域自适应</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/c06123/" class="prev">cowfits竞赛记录</a></span> <span class="next"><a href="/pages/7302ec/">领域自适应</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/eb7136/"><div>Structured Knowledge Distillation for Semantic Segmentation</div></a> <span>06-03</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/83977c/"><div>README 美化</div></a> <span>05-20</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/53d32c/"><div>常见 Tricks 代码片段</div></a> <span>05-12</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:yundoo99@gmail.com" title="发邮件" target="_blank" class="iconfont icon-mail"></a><a href="https://github.com/muyun99" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://muyun.work" title="博客" target="_blank" class="iconfont icon-Blog"></a><a href="https://music.163.com/#/playlist?id=713385758" title="听音乐" target="_blank" class="iconfont icon-icon-test"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2021-2023
    <span>Muyun99 | <a href="https://github.com/Muyun99/Wiki/blob/main/LICENSE" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">跟随系统</li><li class="iconfont icon-rijianmoshi">浅色模式</li><li class="iconfont icon-yejianmoshi">深色模式</li><li class="iconfont icon-yuedu">阅读模式</li></ul></div></div> <!----> <!----> <div class="custom-html-window custom-html-window-rb" style="display:;"><div class="custom-wrapper"><i class="close-but">×</i> <div><!-- 固定160*160px -->
      <ins class="adsbygoogle"
          style="display:inline-block;max-width:160px;max-height:160px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="8377369658"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
      </div></div></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.2164cc85.js" defer></script><script src="/assets/js/2.3a0f33d3.js" defer></script><script src="/assets/js/84.76bc15ac.js" defer></script>
  </body>
</html>