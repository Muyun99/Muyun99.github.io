(window.webpackJsonp=window.webpackJsonp||[]).push([[106],{530:function(e,t,i){"use strict";i.r(t);var s=i(25),a=Object(s.a)({},(function(){var e=this,t=e.$createElement,i=e._self._c||t;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h2",{attrs:{id:"few-shot-learning-竞赛学习-1"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#few-shot-learning-竞赛学习-1"}},[e._v("#")]),e._v(" Few-shot Learning 竞赛学习-1")]),e._v(" "),i("p",[e._v("最近离一个比赛结束还有不到一周，准备来快速学习下 few-shot learning 看能不能摸到奖（大雾）")]),e._v(" "),i("h4",{attrs:{id:"_01、问题描述"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_01、问题描述"}},[e._v("#")]),e._v(" 01、问题描述")]),e._v(" "),i("p",[e._v("1.1 数据描述")]),e._v(" "),i("ul",[i("li",[e._v("训练集有 49990 张图像，分为10类，每张图像的尺寸为 32 x 32\n"),i("ul",[i("li",[e._v("其中有 20 张有标注，每类2张，剩下 49970 张图像无标注")])])]),e._v(" "),i("li",[e._v("验证集有10类，每类1张")]),e._v(" "),i("li",[e._v("测试集有 10000 张")])]),e._v(" "),i("p",[e._v("1.2 竞赛问题定义")]),e._v(" "),i("p",[e._v("按照 Few-shot learning 的定义来讲，训练集中随机抽取 C 个类别，每个类别 K 个样本（总共 CK 个数据），成为C-way K-shot 问题。")]),e._v(" "),i("p",[e._v("该竞赛的任务被定义为 10-way 2-shot 问题，也就是 10 类，每类 2 张有标注")]),e._v(" "),i("h4",{attrs:{id:"_02、竞赛学习"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_02、竞赛学习"}},[e._v("#")]),e._v(" 02、竞赛学习")]),e._v(" "),i("h5",{attrs:{id:"_2-1-参考资料-1-参考资料-2"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-参考资料-1-参考资料-2"}},[e._v("#")]),e._v(" 2.1 参考资料[1] & 参考资料 [2]")]),e._v(" "),i("p",[e._v("这里首先学习下参考资料[1]与参考资料[2]")]),e._v(" "),i("p",[e._v("支撑集（Support Set）：即 C 类，每类 K 个样本所组成的 CK 个数据")]),e._v(" "),i("p",[e._v("查询集（Query Set）：类似测试集，包含 Q 张未分类图像即这里的 10000 张")]),e._v(" "),i("p",[e._v("这里重点关注下 "),i("strong",[e._v("Metric Based 方法")]),e._v("，看起来比较容易实现。Metric Based 方法通过度量 batch 集中的样本和 support 集中样本的距离，借助最近邻的思想完成分类。")]),e._v(" "),i("p",[e._v("度量学习的基本思想是学习单个数据（如图像）之间的距离函数。它已被证明对于解决小样本分类任务非常有效："),i("strong",[e._v("度量学习算法通过将查询集图像与已标记的支持集图像进行比较来进行分类。")])]),e._v(" "),i("ul",[i("li",[e._v("将支持集和查询集的所有图像提取 Embedding，")]),e._v(" "),i("li",[e._v("查询集中的每张图像都根据其与支持集图像的距离来进行分类，例如欧氏距离/余弦距离 以及 KNN 算法")])]),e._v(" "),i("p",[e._v("可以使用孪生网络（Siamese Network）")]),e._v(" "),i("ul",[i("li",[i("p",[e._v("训练时，通过组合的方式构造不同的成对样本，输入网络进行训练，在最上层通过样本对的距离来判断他们是否属于同一类，并产生对应的概率分布。")])]),e._v(" "),i("li",[i("p",[e._v("在预测阶段，将测试样本集和支撑集之间每一个样本对都进行推理，预测结果为支撑集上概率最高的类别")])])]),e._v(" "),i("p",[e._v("可以使用原型网络（Prototype Network）")]),e._v(" "),i("ul",[i("li",[e._v("每个类都存在一个原型表达，该类的原型是 support set 在 embedding 空间中的均值")]),e._v(" "),i("li",[e._v("分类问题即可变成在 embedding 空间中的最近邻问题")])]),e._v(" "),i("p",[e._v("Relation Network")]),e._v(" "),i("ul",[i("li",[e._v("认为度量方式也是网络中重要的一环，需要对其进行建模")])]),e._v(" "),i("p",[e._v("该文章提出了统一的 Encode-Induction-Relation 描述框架")]),e._v(" "),i("h5",{attrs:{id:"_2-2-参考资料-3"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-参考资料-3"}},[e._v("#")]),e._v(" 2.2 参考资料[3]")]),e._v(" "),i("p",[e._v("参考资料[3] 解释了 Meta-learning 方法的步骤")]),e._v(" "),i("p",[e._v("训练时")]),e._v(" "),i("ul",[i("li",[i("p",[e._v("将训练集采样成 Support Set 以及 Query Set")])]),e._v(" "),i("li",[i("p",[e._v("基于Support Set 生成分类模型 F")])]),e._v(" "),i("li",[i("p",[e._v("利用模型 F 对 Query Set 进行分类预测生成 predict labels（pseudo-label）")])]),e._v(" "),i("li",[i("p",[e._v("通过 query labels 和 predicted labels 进行 loss 的计算，从而更新网络参数")])])]),e._v(" "),i("p",[e._v("测试时：")]),e._v(" "),i("ul",[i("li",[e._v("利用分类模型 F 对 Query Set 进行预测")])]),e._v(" "),i("h5",{attrs:{id:"_2-3-参考资料-4"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-参考资料-4"}},[e._v("#")]),e._v(" 2.3 参考资料[4]")]),e._v(" "),i("p",[e._v("参考资料[4] 介绍了Metric Learning 中的损失函数")]),e._v(" "),i("ul",[i("li",[e._v("Contrastive loss\n"),i("ul",[i("li",[e._v("输入：两个样本组成的样本对，label 为该样本对是否属于同一类")]),e._v(" "),i("li",[e._v("超参数 maigin，表示不同类样本之间的距离应该超过该 margin 值")])])]),e._v(" "),i("li",[e._v("Triplet loss：\n"),i("ul",[i("li",[e._v("输入：一个三元组，query + positive sample + negative sample")]),e._v(" "),i("li",[e._v("Triplet loss 要求 query 到 负样本的距离与 query 到正样本的距离之差要大于 margin 值")]),e._v(" "),i("li",[e._v("Contrastive loss和triplet loss都很常用，一般来说，Triplet-Loss 的效果比 Contrastive Loss 的效果要好，因为他考虑了正负样本与锚点的距离关系。然而，这两种loss函数如果单独使用则会遭遇收敛速度慢的问题。在学习过程的后期，大多数样本都能满足损失函数的约束条件，这些样本对应进一步学习的贡献很小。因此，这两种损失函数都需要配合hard sample mining的学习策略一起使用，例如 FaceNet 提出的 simi-hard negative sample mining方法。")])])]),e._v(" "),i("li",[e._v("N-pair-ms loss\n"),i("ul",[i("li",[e._v("考虑 query 与多个类别的负样本之间的关系，促使 query 与其他所有类之间都保持距离，能够加快模型的收敛速度")])])]),e._v(" "),i("li",[e._v("Lifted Struct loss\n"),i("ul",[i("li",[e._v("基于 mini-batch 中的所有正负样本对来计算 loss")]),e._v(" "),i("li",[e._v("对于每一个正样本对{i，j}，挖掘出最困难的负样本，与 i 和 j 距离最近的负样本用于计算 triplet loss")]),e._v(" "),i("li",[e._v("优点：动态构建最困难的三元组")])])]),e._v(" "),i("li",[e._v("Ranked list loss\n"),i("ul",[i("li",[e._v("上述方法的缺点\n"),i("ul",[i("li",[e._v("上述损失函数提出加入负样本来获得结构化的信息，但是使用的负样本只是一小部分")]),e._v(" "),i("li",[e._v("这些损失函数没有考虑类内的数据分布，都追求将同一类压缩到同一个点上")])])]),e._v(" "),i("li")])]),e._v(" "),i("li",[e._v("Multi-Similarity loss\n"),i("ul",[i("li",[e._v("自相似性：根据样本对自身计算出的相似性，这是一种最常用也是最重要的相似性。例如，当一个负样本对的余弦相似性较大时，意味着很难把该样本对所对应的两种类别区分开来，这样的样本对对模型来说是困难的，也是有信息量的，对于模型学习更有区分度的特征很有帮助。另一方面，自相似性很难完整地描述embedding空间的样本分布情况。")]),e._v(" "),i("li",[e._v("正相对相似性：不仅考虑当前样本对自身的相似性，还考虑局部邻域内正样本对之间的相对关系。")]),e._v(" "),i("li",[e._v("负相对相似性：不仅考虑当前样本对自身的相似性，还考虑局部邻域内负样本对之间的相对关系。")])])])]),e._v(" "),i("h5",{attrs:{id:"_2-4-参考资料-5"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-参考资料-5"}},[e._v("#")]),e._v(" 2.4 参考资料 [5]")]),e._v(" "),i("p",[e._v("[5] 中比较清晰地说出了几种方法")]),e._v(" "),i("ul",[i("li",[e._v("度量学习：提特征，算距离，KNN 等方式分类")]),e._v(" "),i("li",[e._v("FSL 定制的数据增强：增加数据的量用于 fine-tuning")]),e._v(" "),i("li",[e._v("元学习：在任务级别上学习而不是在样本上学习")])]),e._v(" "),i("h5",{attrs:{id:"_2-5-paperwithcode-sota-论文的方法"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-5-paperwithcode-sota-论文的方法"}},[e._v("#")]),e._v(" 2.5 Paperwithcode SOTA 论文的方法")]),e._v(" "),i("ul",[i("li",[i("a",{attrs:{href:"https://paperswithcode.com/sota/image-clustering-on-cifar-100",target:"_blank",rel:"noopener noreferrer"}},[e._v("Image Clustering on CIFAR-100"),i("OutboundLink")],1),e._v(" "),i("ul",[i("li",[e._v("Accuracy 0.584：https://paperswithcode.com/paper/spice-semantic-pseudo-labeling-for-image")]),e._v(" "),i("li",[e._v("Accuracy 0.543：https://paperswithcode.com/paper/improving-unsupervised-image-clustering-with")]),e._v(" "),i("li",[e._v("Accuracy 0.507：https://paperswithcode.com/paper/learning-to-classify-images-without-labels")])])]),e._v(" "),i("li",[i("a",{attrs:{href:"https://paperswithcode.com/sota/few-shot-image-classification-on-cifar-fs-5",target:"_blank",rel:"noopener noreferrer"}},[e._v("Few-Shot Image Classification on CIFAR-FS 5-way (1-shot)"),i("OutboundLink")],1),e._v(" "),i("ul",[i("li",[e._v("Accuracy  87.79：https://paperswithcode.com/paper/transfer-learning-based-few-shot")]),e._v(" "),i("li",[e._v("Accuracy  87.73：https://paperswithcode.com/paper/sill-net-feature-augmentation-with-separated")]),e._v(" "),i("li",[e._v("Accuracy  87.69：https://paperswithcode.com/paper/leveraging-the-feature-distribution-in")])])])]),e._v(" "),i("h5",{attrs:{id:"_2-6-kaggle-竞赛的方法"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-6-kaggle-竞赛的方法"}},[e._v("#")]),e._v(" 2.6 kaggle 竞赛的方法")]),e._v(" "),i("p",[e._v("参考资料[6] 和[7] 两篇是知乎 “砍手豪” 大神所写的 kaggle 上 few-shot 竞赛的文章，值得学习，可以先看看是否能找到 baseline.")]),e._v(" "),i("ul",[i("li",[i("p",[e._v("tricks")]),e._v(" "),i("ul",[i("li",[e._v("实现 LR finder")])])]),e._v(" "),i("li",[i("p",[e._v("EDA")]),e._v(" "),i("ul",[i("li",[e._v("查找重复图像")]),e._v(" "),i("li",[e._v("模型可视化：https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563")]),e._v(" "),i("li",[e._v("t-SNE 特征可视化")])])]),e._v(" "),i("li",[i("p",[e._v("Siamese Network 神经网络")]),e._v(" "),i("ul",[i("li",[i("strong",[e._v("Siamese神经网络")]),e._v("比较两个图像，并确定这两个图像是从同一条鲸鱼还是从不同的鲸鱼中获取")]),e._v(" "),i("li",[e._v("https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563/data")]),e._v(" "),i("li",[e._v("https://www.kaggle.com/seesee/siamese-pretrained-0-822")]),e._v(" "),i("li",[e._v("https://www.kaggle.com/voglinio/siamese-two-pretrained-weights-0-855")])])]),e._v(" "),i("li",[i("p",[e._v("Metric Learning 神经网络")]),e._v(" "),i("ul",[i("li",[e._v("Metric Learning 使用网络提取 Embedding，再比较 Embedding 之间的距离来进行分类")]),e._v(" "),i("li",[e._v("https://www.kaggle.com/c/humpback-whale-identification/discussion/74647")]),e._v(" "),i("li",[e._v("https://www.kaggle.com/iafoss/similarity-densenet121-0-805lb-kernel-time-limit")])])]),e._v(" "),i("li",[i("p",[e._v("Winner model")]),e._v(" "),i("ul",[i("li",[e._v("1st solution: https://www.kaggle.com/c/humpback-whale-identification/discussion/82366\n"),i("ul",[i("li",[e._v("四通道：RGB + Masks 作为输入（我们可以将RGB + Edges + Masks 作为输入）")])])]),e._v(" "),i("li",[e._v("2nd solution: https://www.kaggle.com/c/humpback-whale-identification/discussion/83885\n"),i("ul",[i("li",[e._v("三种 loss：arcface loss + triplet loss + focal loss")]),e._v(" "),i("li",[e._v("三个backbone：resnet101，seresnet101，seresnext101")])])]),e._v(" "),i("li",[e._v("4th solution: https://www.kaggle.com/c/humpback-whale-identification/discussion/82356\n"),i("ul",[i("li",[e._v("4th Place Solution: SIFT + Siamese")]),e._v(" "),i("li",[e._v("介绍了一些降低复杂度的方法")])])])])])]),e._v(" "),i("h5",{attrs:{id:"_2-7-其他方法"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#_2-7-其他方法"}},[e._v("#")]),e._v(" 2.7 其他方法")]),e._v(" "),i("ul",[i("li",[i("p",[i("a",{attrs:{href:"https://github.com/facebookresearch/deepcluster",target:"_blank",rel:"noopener noreferrer"}},[e._v("Deep Clustering"),i("OutboundLink")],1)]),e._v(" "),i("ul",[i("li",[e._v("https://vissl.readthedocs.io/en/latest/ssl_approaches/deepclusterv2.html")]),e._v(" "),i("li",[e._v("https://github.com/facebookresearch/vissl/blob/master/docs/source/ssl_approaches/deepclusterv2.rst")])])]),e._v(" "),i("li",[i("p",[e._v("Simsiam")]),e._v(" "),i("ul",[i("li",[e._v("https://github.com/facebookresearch/simsiam")])])])]),e._v(" "),i("p",[e._v("孪生网络和对比学习有什么不同？")]),e._v(" "),i("ul",[i("li",[e._v("孪生网络一般针对半监督问题设置")]),e._v(" "),i("li",[e._v("对比学习一般针对无监督问题设置")]),e._v(" "),i("li")]),e._v(" "),i("p",[e._v("2.2 Rotation Loss 是什么")]),e._v(" "),i("h4",{attrs:{id:"参考资料"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[e._v("#")]),e._v(" 参考资料")]),e._v(" "),i("ul",[i("li",[i("p",[e._v("[1] https://zhuanlan.zhihu.com/p/61215293")])]),e._v(" "),i("li",[i("p",[e._v("[2] https://zhuanlan.zhihu.com/p/110075024")])]),e._v(" "),i("li",[i("p",[e._v("[3] https://zhuanlan.zhihu.com/p/149983811")])]),e._v(" "),i("li",[i("p",[e._v("[4] https://zhuanlan.zhihu.com/p/82199561")])]),e._v(" "),i("li",[i("p",[e._v("[5] https://zhuanlan.zhihu.com/p/258562899")])]),e._v(" "),i("li",[i("p",[e._v("[6] https://zhuanlan.zhihu.com/p/87969454")])]),e._v(" "),i("li",[i("p",[e._v("[7] https://zhuanlan.zhihu.com/p/111644699")])])])])}),[],!1,null,null,null);t.default=a.exports}}]);