(window.webpackJsonp=window.webpackJsonp||[]).push([[163],{587:function(a,e,t){"use strict";t.r(e);var r=t(25),s=Object(r.a)({},(function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h3",{attrs:{id:"_1、图游走类算法简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、图游走类算法简介"}},[a._v("#")]),a._v(" 1、图游走类算法简介")]),a._v(" "),t("p",[a._v("目标：Node embeddings。得到节点的低维表示，学习到节点与邻居的关系，更好地表示节点信息，再用于下游任务")]),a._v(" "),t("p",[a._v("方法：多次游走，得到游走序列，类似于NLP领域的Word2vec模型：词的语义由其上下文决定")]),a._v(" "),t("h3",{attrs:{id:"_2、word2vec"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、word2vec"}},[a._v("#")]),a._v(" 2、Word2vec")]),a._v(" "),t("h4",{attrs:{id:"_2-1-word2vec-skip-gram"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-word2vec-skip-gram"}},[a._v("#")]),a._v(" 2.1 Word2vec：Skip Gram")]),a._v(" "),t("p",[a._v("通过给定中心词预测上下文这个任务，得到Hidden layer的参数，通过Hidden Layer即可得到词的Embedding。")]),a._v(" "),t("p",[t("img",{attrs:{src:"https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/picgo/image-20210628114348190.png",alt:"image-20210628114348190"}})]),a._v(" "),t("h4",{attrs:{id:"_2-2-word2vec-negative-sampling"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-word2vec-negative-sampling"}},[a._v("#")]),a._v(" 2.2 Word2vec：Negative Sampling")]),a._v(" "),t("p",[a._v("softmax需要对上下文的每个词都预测一个概率，计算量很大")]),a._v(" "),t("p",[a._v("提出负采样（Negative Sampling），得到正样本和负样本，做一个分类任务，将 Softmax 变为 Multiple sigmoid")]),a._v(" "),t("h3",{attrs:{id:"_3、word2vec-图浅入领域"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、word2vec-图浅入领域"}},[a._v("#")]),a._v(" 3、Word2vec->图浅入领域")]),a._v(" "),t("h4",{attrs:{id:"_3-1-图游走类模型-deepwalk"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-图游走类模型-deepwalk"}},[a._v("#")]),a._v(" 3.1 图游走类模型-DeepWalk")]),a._v(" "),t("p",[a._v("通过随机游走得到NLP领域中的“句子”，得到多个游走序列，本质就是可以回头的DFS")]),a._v(" "),t("p",[a._v("15：50")])])}),[],!1,null,null,null);e.default=s.exports}}]);