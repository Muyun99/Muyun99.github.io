(window.webpackJsonp=window.webpackJsonp||[]).push([[130],{554:function(t,a,s){"use strict";s.r(a);var i=s(25),e=Object(i.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"valse-webinar-20-02-元学习与小样本学习"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#valse-webinar-20-02-元学习与小样本学习"}},[t._v("#")]),t._v(" VALSE Webinar 20-02 元学习与小样本学习")]),t._v(" "),s("h3",{attrs:{id:"_01、siyuan-qiao-jhu"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_01、siyuan-qiao-jhu"}},[t._v("#")]),t._v(" 01、Siyuan Qiao JHU")]),t._v(" "),s("h4",{attrs:{id:"few-shot-image-recognition-by-predictiong-parameters-from-activations-cvpr-2018"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#few-shot-image-recognition-by-predictiong-parameters-from-activations-cvpr-2018"}},[t._v("#")]),t._v(" Few-Shot Image Recognition by Predictiong Parameters from Activations (CVPR 2018)")]),t._v(" "),s("p",[t._v("m-shot n-way image recognition")]),t._v(" "),s("ul",[s("li",[t._v("m-shot: each new class has m training images")]),t._v(" "),s("li",[t._v("n-way: predict the class of test images from n classes")])]),t._v(" "),s("p",[t._v("Few-shot + large-scale image recognition")]),t._v(" "),s("ul",[s("li",[t._v("pre-training on large-scale datasets(black) and few-shot adaptation to new classes(green).")]),t._v(" "),s("li",[t._v("有点像 open-set 问题设置")])]),t._v(" "),s("p",[t._v("两个数据集：Few-shot "),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[s("semantics",[s("mrow",[s("msub",[s("mi",[t._v("D")]),s("mrow",[s("mi",[t._v("f")]),s("mi",[t._v("e")]),s("mi",[t._v("w")])],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("D_{few}")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.969438em","vertical-align":"-0.286108em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.02778em"}},[t._v("D")]),s("span",{staticClass:"msupsub"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.3361079999999999em"}},[s("span",{staticStyle:{top:"-2.5500000000000003em","margin-left":"-0.02778em","margin-right":"0.05em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),s("span",{staticClass:"sizing reset-size6 size3 mtight"},[s("span",{staticClass:"mord mtight"},[s("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.10764em"}},[t._v("f")]),s("span",{staticClass:"mord mathnormal mtight"},[t._v("e")]),s("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.02691em"}},[t._v("w")])])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.286108em"}},[s("span")])])])])])])])]),t._v(" 和 "),s("span",{staticClass:"katex"},[s("span",{staticClass:"katex-mathml"},[s("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[s("semantics",[s("mrow",[s("msub",[s("mi",[t._v("D")]),s("mrow",[s("mi",[t._v("l")]),s("mi",[t._v("a")]),s("mi",[t._v("r")]),s("mi",[t._v("g")]),s("mi",[t._v("e")])],1)],1)],1),s("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("D_{large}")])],1)],1)],1),s("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[s("span",{staticClass:"base"},[s("span",{staticClass:"strut",staticStyle:{height:"0.969438em","vertical-align":"-0.286108em"}}),s("span",{staticClass:"mord"},[s("span",{staticClass:"mord mathnormal",staticStyle:{"margin-right":"0.02778em"}},[t._v("D")]),s("span",{staticClass:"msupsub"},[s("span",{staticClass:"vlist-t vlist-t2"},[s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.3361079999999999em"}},[s("span",{staticStyle:{top:"-2.5500000000000003em","margin-left":"-0.02778em","margin-right":"0.05em"}},[s("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),s("span",{staticClass:"sizing reset-size6 size3 mtight"},[s("span",{staticClass:"mord mtight"},[s("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.01968em"}},[t._v("l")]),s("span",{staticClass:"mord mathnormal mtight"},[t._v("a")]),s("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.02778em"}},[t._v("r")]),s("span",{staticClass:"mord mathnormal mtight",staticStyle:{"margin-right":"0.03588em"}},[t._v("g")]),s("span",{staticClass:"mord mathnormal mtight"},[t._v("e")])])])])]),s("span",{staticClass:"vlist-s"},[t._v("​")])]),s("span",{staticClass:"vlist-r"},[s("span",{staticClass:"vlist",staticStyle:{height:"0.286108em"}},[s("span")])])])])])])])])]),t._v(" "),s("p",[t._v("目标：在两个数据集上效果都比较优异")]),t._v(" "),s("p",[t._v("两个小tricks:")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("Multi-View：")])]),t._v(" "),s("li",[s("p",[t._v("集成学习， 学两个映射")])])]),t._v(" "),s("h3",{attrs:{id:"_02、deyu-meng-xjtu"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_02、deyu-meng-xjtu"}},[t._v("#")]),t._v(" 02、Deyu Meng XJTU")]),t._v(" "),s("p",[t._v("鲁棒深度学习与元学习")]),t._v(" "),s("ul",[s("li",[s("p",[t._v("深度学习：标注质量很高的数据集，但是现实情况中数据是存在偏差的（Data bias），例如小样本、弱监督、标签带噪")]),t._v(" "),s("ul",[s("li",[t._v("Label Noise：标签是带有噪声的")]),t._v(" "),s("li",[t._v("Data Noise：数据本身带有噪声的")]),t._v(" "),s("li",[t._v("Class imbalance：类别不平衡")])])]),t._v(" "),s("li",[s("p",[t._v("鲁棒学习")]),t._v(" "),s("ul",[s("li",[t._v("设计不同的鲁棒优化目标，例如鲁棒的损失函数")]),t._v(" "),s("li",[t._v("化腐朽为神奇：从质量很差的数据集中依然能抽取出我们想要的信息")]),t._v(" "),s("li",[t._v("损失函数\n"),s("ul",[s("li",[t._v("Label Noise\n"),s("ul",[s("li",[t._v("Generalized CE (NeurIPS 2018)")]),t._v(" "),s("li",[t._v("Symmetric CE (ICCV 2019)")]),t._v(" "),s("li",[t._v("Bi-Tempered logistic loss (NeurIPS 2019)")]),t._v(" "),s("li",[t._v("Polynomial Softweighting loss (AAAI 2015)")])])]),t._v(" "),s("li",[t._v("Focal loss (TPAMI 2018)：class imbalance")]),t._v(" "),s("li",[t._v("CT loss (TMI 2018): data noise")]),t._v(" "),s("li",[t._v("问题：需要设置超参数，非凸优化")])])])])]),t._v(" "),s("li",[s("p",[t._v("元学习")])]),t._v(" "),s("li",[s("p",[t._v("验证数据集和训练数据集的区别")]),t._v(" "),s("ul",[s("li",[t._v("验证数据集用于超参数的调整，训练数据集用于分类器参数的学习")])])]),t._v(" "),s("li",[s("p",[t._v("设计一个 Meta loss")]),t._v(" "),s("ul",[s("li",[t._v("Optimization instead of search")]),t._v(" "),s("li",[t._v("Intelligent instead of heuristic (partially)")])])]),t._v(" "),s("li",[s("p",[t._v("Sample Reweighting methods")]),t._v(" "),s("ul",[s("li",[t._v("Self-paced")]),t._v(" "),s("li",[t._v("Linear weighting")]),t._v(" "),s("li",[t._v("Focal Loss")]),t._v(" "),s("li",[t._v("Hard example mining：采样")]),t._v(" "),s("li",[t._v("Prediction variance")])])]),t._v(" "),s("li",[s("p",[t._v("对样本的损失前加一个权重，放大/缩小一些样本损失")]),t._v(" "),s("ul",[s("li",[t._v("出现了截然不同的两种加权策略\n"),s("ul",[s("li",[t._v("误差大权重小，误差小权重大：认为误差大的样本是噪声样本（label noise）")]),t._v(" "),s("li",[t._v("误差大权重大，误差小权重小：认为误差大的样本是难样本（class imbalance $ ohem）")])])]),t._v(" "),s("li",[t._v("使用 Meta Learning，将样本权重当做超参数去学出来\n"),s("ul",[s("li",[t._v("MentorNet：V太多了，不能有效地利用前序信息，训练起来不稳定")]),t._v(" "),s("li",[t._v("Meng组的改进：Meta-Weight-Net\n"),s("ul",[s("li",[t._v("Meta-Weight-Net: Learning an Explict Mapping for Sample Weighting. (NeuIPS 2019)")]),t._v(" "),s("li",[t._v("将V变成一个函数，输入是Loss，输出是weight，函数希望既能够拟合单调递增又能够拟合单调递减，所以就用MLP来实现")]),t._v(" "),s("li",[t._v("从下图中可以看出，学的确实不错")]),t._v(" "),s("li",[s("img",{attrs:{src:"https://muyun-blog-pic.oss-cn-shanghai.aliyuncs.com/picgo/image-20210913153013752.png",alt:"image-20210913153013752"}})])])])])])])])])])}),[],!1,null,null,null);a.default=e.exports}}]);